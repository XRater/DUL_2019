{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DUL_HW3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLQte7LQh52r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import torch\n",
        "import torch.distributions as D\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import train_test_split\n",
        "import plotly.graph_objs as go"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YevWtkZ4QC7f",
        "colab_type": "code",
        "outputId": "6bbe95c0-ba81-4451-d105-5afef4b4c3a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(DEVICE)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CLJhImfHjrFG",
        "colab": {}
      },
      "source": [
        "class CouplingBlock(nn.Module):\n",
        "    def __init__(self, channels_number):\n",
        "      super(CouplingBlock, self).__init__()\n",
        "      self.channels_number = channels_number\n",
        "      self.model = nn.Sequential(\n",
        "          nn.Conv2d(self.channels_number, self.channels_number, 1, stride=1),\n",
        "          nn.ReLU(),\n",
        "          nn.Conv2d(self.channels_number, self.channels_number, 3, stride=1, padding=1),\n",
        "          nn.ReLU(),\n",
        "          nn.Conv2d(self.channels_number, self.channels_number, 1, stride=1)\n",
        "      )\n",
        "\n",
        "    def forward(self, x):\n",
        "      return x + self.model(x)\n",
        "\n",
        "class AffineCoupling(nn.Module):\n",
        "    def __init__(self, in_channels, n_filters=256, n_blocks=8):\n",
        "      super(AffineCoupling, self).__init__()\n",
        "      self.n_filters = n_filters\n",
        "      self.in_channels = in_channels\n",
        "      self.out_channels = in_channels * 2\n",
        "      self.n_blocks = n_blocks\n",
        "\n",
        "      self.first_conv = nn.Conv2d(self.in_channels, self.n_filters, 3, stride=1, padding=1)\n",
        "      self.layers = nn.Sequential(*[CouplingBlock(self.n_filters) for _ in range(self.n_blocks)])\n",
        "      self.relu = nn.ReLU()\n",
        "      self.last_conv = nn.Conv2d(self.n_filters, self.out_channels, 3, stride=1, padding=1)\n",
        "\n",
        "    def forward(self, data):\n",
        "      (x1, x2), loss = data\n",
        "      y1 = x1\n",
        "      s, t = torch.chunk(self.simple_resnet(x1), 2, dim=1)\n",
        "      y2 = torch.exp(s) * x2 + t\n",
        "      loss = loss + torch.abs(s.reshape(x1.shape[0], -1).sum(dim=1))\n",
        "      return ((y1, y2), loss)  \n",
        "\n",
        "    def reverse(self, z):\n",
        "      z1, z2 = z\n",
        "      x1 = z1\n",
        "      s, t = torch.chunk(self.simple_resnet(z1), 2, dim=1)\n",
        "      x2 = z2 * torch.exp(-s) - t\n",
        "      return (x1, x2)\n",
        "\n",
        "    def simple_resnet(self, x):\n",
        "      z = x\n",
        "      z = self.first_conv(z)\n",
        "      z = self.layers(z)\n",
        "      z = self.relu(z)\n",
        "      z = self.last_conv(z)\n",
        "      return z"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1lc5P2Ygy96",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FlipModel(nn.Module):\n",
        "    def __init__(self):\n",
        "      super(FlipModel, self).__init__()\n",
        "\n",
        "    def forward(self, data):\n",
        "      (x1, x2), loss = data\n",
        "      return (x2, x1), loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znunwIxp7Qf5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AffineWithFlip(nn.Module):\n",
        "  def __init__(self, in_channels):\n",
        "    super(AffineWithFlip, self).__init__()\n",
        "    self.in_channels = in_channels\n",
        "    self.model = nn.Sequential(\n",
        "        AffineCoupling(in_channels),\n",
        "        FlipModel()\n",
        "    )\n",
        "\n",
        "  def forward(self, data):\n",
        "    return self.model(data)\n",
        "\n",
        "  def reverse(self, z):\n",
        "    z1, z2 = z\n",
        "    return self.model[0].reverse((z2, z1))\n",
        "\n",
        "class RealNVPModel(nn.Module):\n",
        "\n",
        "  def __init__(self, in_channels):\n",
        "    super(RealNVPModel, self).__init__()\n",
        "    self.prior = D.Normal(torch.tensor(0.).to(DEVICE), torch.tensor(1.).to(DEVICE))\n",
        "    self.in_channels = in_channels\n",
        "    self.affineCoupling1 = nn.Sequential(*[AffineWithFlip(self.in_channels) for _ in range(4)])\n",
        "    self.affineCoupling2 = nn.Sequential(*[AffineWithFlip(self.in_channels * 2) for _ in range(3)])\n",
        "    self.affineCoupling3 = nn.Sequential(*[AffineWithFlip(self.in_channels * 4) for _ in range(3)])\n",
        "    self.affineCoupling4 = nn.Sequential(*[AffineWithFlip(self.in_channels * 8) for _ in range(3)])\n",
        "    self.affineCoupling5 = nn.Sequential(*[AffineWithFlip(self.in_channels * 16) for _ in range(3)])\n",
        "\n",
        "  def forward(self, x):\n",
        "    data, loss = self.preprocess(x), torch.zeros(x.shape[0]).to(DEVICE)\n",
        "    data, loss = self.withCheckBoardSplit(data, loss, self.affineCoupling1)\n",
        "    data = self.squeeze(data)\n",
        "    data, loss = self.withChannelSplit(data, loss, self.affineCoupling2)\n",
        "    data, loss = self.withCheckBoardSplit(data, loss, self.affineCoupling3)\n",
        "    data = self.squeeze(data)\n",
        "    data, loss = self.withChannelSplit(data, loss, self.affineCoupling4)\n",
        "    data, loss = self.withCheckBoardSplit(data, loss, self.affineCoupling5)\n",
        "    loss = loss + torch.sum(self.prior.log_prob(data), dim=(1, 2, 3))\n",
        "    return data, loss\n",
        "\n",
        "  def reverse(self, z):\n",
        "    loss = 0\n",
        "    z, loss = self.withCheckBoardSplit(z, loss, self.affineCoupling5, True)\n",
        "    z, loss = self.withChannelSplit(z, loss, self.affineCoupling4, True)\n",
        "    z = self.unsqueeze(z)\n",
        "    z, loss = self.withCheckBoardSplit(z, loss, self.affineCoupling3, True)\n",
        "    z, loss = self.withChannelSplit(z, loss, self.affineCoupling2, True)\n",
        "    z = self.unsqueeze(z)\n",
        "    z, loss = self.withCheckBoardSplit(z, loss, self.affineCoupling1, True)\n",
        "    return z\n",
        "\n",
        "  def squeeze(self, data):\n",
        "    N, C, W, H = data.shape\n",
        "    mask1 = torch.tensor([[True, False], [False, False]]).repeat(N, C, W//2, H//2).to(DEVICE)\n",
        "    x1 = torch.masked_select(data, mask1).reshape(N, C, W//2, H//2)\n",
        "    mask2 = torch.tensor([[False, True], [False, False]]).repeat(N, C, W//2, H//2).to(DEVICE)\n",
        "    x2 = torch.masked_select(data, mask2).reshape(N, C, W//2, H//2)\n",
        "    mask3 = torch.tensor([[False, False], [True, False]]).repeat(N, C, W//2, H//2).to(DEVICE)\n",
        "    x3 = torch.masked_select(data, mask3).reshape(N, C, W//2, H//2)\n",
        "    mask4 = torch.tensor([[False, False], [False, True]]).repeat(N, C, W//2, H//2).to(DEVICE)\n",
        "    x4 = torch.masked_select(data, mask4).reshape(N, C, W//2, H//2)\n",
        "    return torch.cat([x1, x2, x3, x4], dim=1)\n",
        "\n",
        "  def unsqueeze(self, data):\n",
        "    N, C, W, H = data.shape\n",
        "    C, W, H = C // 4, W * 2, H * 2\n",
        "    x1, x2, x3, x4 = torch.chunk(data, 4, dim=1)\n",
        "    x = torch.zeros(N, C, W, H).to(DEVICE)\n",
        "    mask1 = torch.tensor([[True, False], [False, False]]).repeat(N, C, W//2, H//2).to(DEVICE)\n",
        "    mask2 = torch.tensor([[False, True], [False, False]]).repeat(N, C, W//2, H//2).to(DEVICE)\n",
        "    mask3 = torch.tensor([[False, False], [True, False]]).repeat(N, C, W//2, H//2).to(DEVICE)\n",
        "    mask4 = torch.tensor([[False, False], [False, True]]).repeat(N, C, W//2, H//2).to(DEVICE)\n",
        "    x[mask1] = x1.reshape(-1)\n",
        "    x[mask2] = x2.reshape(-1)\n",
        "    x[mask3] = x3.reshape(-1)\n",
        "    x[mask4] = x4.reshape(-1)\n",
        "    return x\n",
        "\n",
        "  def withCheckBoardSplit(self, data, loss, layer, reverse=False):\n",
        "    data = self.checkBoardSplit(data)\n",
        "    if reverse:\n",
        "      for item in reversed(layer):        \n",
        "        data, loss = item.reverse(data), loss\n",
        "    else:\n",
        "      data, loss = layer((data, loss))\n",
        "    data = self.inverseCheckBoardSplit(data)\n",
        "    return data, loss\n",
        "\n",
        "  def withChannelSplit(self, data, loss, layer, reverse=False):\n",
        "    data = self.channelSplit(data)\n",
        "    if reverse:\n",
        "      for item in reversed(layer):        \n",
        "        data, loss = item.reverse(data), loss\n",
        "    else:\n",
        "      data, loss = layer((data, loss))\n",
        "    data = self.inverseChannelSplit(data)\n",
        "    return data, loss\n",
        "\n",
        "  def checkBoardSplit(self, data):\n",
        "    N, C, W, H = data.shape\n",
        "    mask = torch.tensor([[True, False], [False, True]]).repeat(N, C, W//2, H//2).to(DEVICE)\n",
        "    x1 = torch.masked_select(data, mask).reshape(N, C, -1)\n",
        "    x2 = torch.masked_select(data, ~mask).reshape(N, C, -1)\n",
        "    return (x1.reshape(N, C, W, H // 2), x2.reshape(N, C, W, H // 2))\n",
        "\n",
        "  def inverseCheckBoardSplit(self, data):\n",
        "    x1, x2 = data\n",
        "    N, C, W, H = x1.shape\n",
        "    H = H * 2\n",
        "    data = torch.zeros(N, C, W, H).to(DEVICE)\n",
        "    mask1 = torch.tensor([[True, False], [False, True]]).repeat(N, C, W//2, H//2).to(DEVICE)\n",
        "    mask2 = torch.tensor([[False, True], [True, False]]).repeat(N, C, W//2, H//2).to(DEVICE)\n",
        "    data[mask1] = x1.reshape(-1)\n",
        "    data[mask2] = x2.reshape(-1)\n",
        "    return data\n",
        "\n",
        "  def channelSplit(self, data):\n",
        "    return (torch.chunk(data, 2, dim=1))\n",
        "\n",
        "  def inverseChannelSplit(self, data):\n",
        "    x1, x2 = data\n",
        "    return torch.cat((x1, x2), dim=1)\n",
        "\n",
        "  def preprocess(self, x):\n",
        "    return x\n",
        "\n",
        "  def sample(self, N, C, W, H):\n",
        "    z = self.prior.sample((size, C * 18, W // 4, H // 4))\n",
        "    return self.reverse(z)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lbOSAsdLYke",
        "colab_type": "code",
        "outputId": "61b36001-0015-4fe0-b187-92774d41336a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5D7_oKVy-Xd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data():\n",
        "  def prepare_data(data):\n",
        "    data = torch.from_numpy(data).float()\n",
        "    data = data / 3\n",
        "    data = data.transpose(1, 3)\n",
        "    data = data.transpose(2, 3)\n",
        "    return data\n",
        "\n",
        "  dataset_path = '/content/drive/My Drive/dataset/hw2_q2.pkl'\n",
        "\n",
        "  with open(dataset_path, 'rb') as f:\n",
        "      dataset = pickle.load(f)\n",
        "\n",
        "  return prepare_data(dataset['train']), prepare_data(dataset['test'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YG7OOb1znv9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data, test_data = load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUsJ2U_H4AQ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, optimizer, train_loader, test_loader, num_epochs):\n",
        "  for epoch in range(num_epochs):\n",
        "    loss, val_loss = 0, 0\n",
        "    iteration = 0\n",
        "    for batch in train_loader:\n",
        "      batch = batch.to(DEVICE)\n",
        "      iteration = iteration + 1\n",
        "      optimizer.zero_grad()\n",
        "      data, curr_loss = model(batch)\n",
        "      curr_loss = curr_loss.mean()\n",
        "      loss += curr_loss.item()\n",
        "      curr_loss.backward()\n",
        "      optimizer.step()\n",
        "      print(f\"iteration is {iteration}, curr_loss is ${curr_loss}, total loss is ${loss / iteration}\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for batch in test_loader:\n",
        "        batch = batch.to(DEVICE)\n",
        "        data, curr_loss = model(batch)\n",
        "        val_loss += curr_loss.mean()\n",
        "\n",
        "    print(f\"After epoch {epoch} loss is {loss / len(train_loader)} and validation loss is {val_loss / len(test_loader)}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cv69kcWK6oS4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_realNVP_model_train(train_data, test_data):\n",
        "  batch_size = 8\n",
        "  num_epochs = 10\n",
        "\n",
        "  model = RealNVPModel(3)\n",
        "  model = model.to(DEVICE)\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "  train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "  test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size)\n",
        "  train(model, optimizer, train_loader, test_loader, num_epochs)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}